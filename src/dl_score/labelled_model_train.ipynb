{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import requests\n",
    "import pickle\n",
    "load_dotenv(\"./.env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>address</th>\n",
       "      <th>career_objective</th>\n",
       "      <th>skills</th>\n",
       "      <th>educational_institution_name</th>\n",
       "      <th>degree_names</th>\n",
       "      <th>passing_years</th>\n",
       "      <th>educational_results</th>\n",
       "      <th>result_types</th>\n",
       "      <th>major_field_of_studies</th>\n",
       "      <th>professional_company_names</th>\n",
       "      <th>...</th>\n",
       "      <th>online_links</th>\n",
       "      <th>issue_dates</th>\n",
       "      <th>expiry_dates</th>\n",
       "      <th>﻿job_position_name</th>\n",
       "      <th>educationaL_requirements</th>\n",
       "      <th>experiencere_requirement</th>\n",
       "      <th>age_requirement</th>\n",
       "      <th>responsibilities.1</th>\n",
       "      <th>skills_required</th>\n",
       "      <th>matched_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2584</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['C#', 'ASP.NET', 'Visual Basic', 'Ms Visual S...</td>\n",
       "      <td>['University of Texas Arlington', 'Federal Uni...</td>\n",
       "      <td>['Master of Science', 'Bachelor of Engineering']</td>\n",
       "      <td>['December 2014', 'June 2004']</td>\n",
       "      <td>['4.00', 'N/A']</td>\n",
       "      <td>['GPA', 'N/A']</td>\n",
       "      <td>['Industrial and Manufacturing Engineering', '...</td>\n",
       "      <td>['Company Name', 'Company Name', 'Company Name...</td>\n",
       "      <td>...</td>\n",
       "      <td>[None]</td>\n",
       "      <td>['July 2013']</td>\n",
       "      <td>['N/A']</td>\n",
       "      <td>Executive/ Sr. Executive -IT</td>\n",
       "      <td>Bachelor of Science (BSc) in Computer Science ...</td>\n",
       "      <td>3 to 5 years</td>\n",
       "      <td>Age at most 40 years</td>\n",
       "      <td>Hardware &amp; Software Installation\\nSystem Monit...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.716667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     address career_objective  \\\n",
       "2584     NaN              NaN   \n",
       "\n",
       "                                                 skills  \\\n",
       "2584  ['C#', 'ASP.NET', 'Visual Basic', 'Ms Visual S...   \n",
       "\n",
       "                           educational_institution_name  \\\n",
       "2584  ['University of Texas Arlington', 'Federal Uni...   \n",
       "\n",
       "                                          degree_names  \\\n",
       "2584  ['Master of Science', 'Bachelor of Engineering']   \n",
       "\n",
       "                       passing_years educational_results    result_types  \\\n",
       "2584  ['December 2014', 'June 2004']     ['4.00', 'N/A']  ['GPA', 'N/A']   \n",
       "\n",
       "                                 major_field_of_studies  \\\n",
       "2584  ['Industrial and Manufacturing Engineering', '...   \n",
       "\n",
       "                             professional_company_names  ... online_links  \\\n",
       "2584  ['Company Name', 'Company Name', 'Company Name...  ...       [None]   \n",
       "\n",
       "        issue_dates expiry_dates            ﻿job_position_name  \\\n",
       "2584  ['July 2013']      ['N/A']  Executive/ Sr. Executive -IT   \n",
       "\n",
       "                               educationaL_requirements  \\\n",
       "2584  Bachelor of Science (BSc) in Computer Science ...   \n",
       "\n",
       "     experiencere_requirement       age_requirement  \\\n",
       "2584             3 to 5 years  Age at most 40 years   \n",
       "\n",
       "                                     responsibilities.1 skills_required  \\\n",
       "2584  Hardware & Software Installation\\nSystem Monit...             NaN   \n",
       "\n",
       "     matched_score  \n",
       "2584      0.716667  \n",
       "\n",
       "[1 rows x 35 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"./../data/labelled_resume_data.csv\")\n",
    "df.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to select the top two entities from a list and make separate dataframe columns\n",
    "\n",
    "# Date parsing functions\n",
    "def parse_date(date_str):\n",
    "    try:\n",
    "        if pd.isna(date_str):\n",
    "            return pd.NaT\n",
    "        if isinstance(date_str, list):\n",
    "            date_str = date_str[0]\n",
    "        if isinstance(date_str, str) and date_str.strip() in ['Present', 'Till Date']:\n",
    "            return pd.Timestamp.today()\n",
    "            \n",
    "        # Try specific formats first\n",
    "        for fmt in ['%b %Y', '%B %Y', '%Y-%m-%d', '%Y/%m/%d', '%d-%m-%Y', '%d/%m/%Y']:\n",
    "            try:\n",
    "                return pd.to_datetime(date_str, format=fmt)\n",
    "            except (ValueError, TypeError):\n",
    "                continue\n",
    "                \n",
    "        # Fall back to pandas default parser\n",
    "        return pd.to_datetime(date_str)\n",
    "    except Exception as e:\n",
    "        print(f\"Error parsing date '{date_str}': {str(e)}\")\n",
    "        return pd.NaT\n",
    "    \n",
    "def get_top_two_entities(df: pd.DataFrame, column: str) -> pd.DataFrame:\n",
    "    # Create new columns first\n",
    "    df[f\"{column}_1\"] = None\n",
    "    df[f\"{column}_2\"] = None\n",
    "    \n",
    "    for i, row in df.iterrows():\n",
    "        entities = str(row[column]).split(',')  # Convert to string and split\n",
    "        entities = [e.strip() for e in entities]  # Strip whitespace\n",
    "        \n",
    "        if len(entities) > 1:\n",
    "            df.at[i, f\"{column}_1\"] = entities[0]  # Using .at is more efficient for single value\n",
    "            df.at[i, f\"{column}_2\"] = entities[1]\n",
    "        else:\n",
    "            df.at[i, f\"{column}_1\"] = entities[0]\n",
    "            df.at[i, f\"{column}_2\"] = None\n",
    "    \n",
    "    return df\n",
    "\n",
    "def get_top_four_entities(df: pd.DataFrame, column: str) -> pd.DataFrame:\n",
    "    # Create new columns first\n",
    "    df[f\"{column}_1\"] = None\n",
    "    df[f\"{column}_2\"] = None\n",
    "    df[f\"{column}_3\"] = None\n",
    "    df[f\"{column}_4\"] = None\n",
    "    \n",
    "    for i, row in df.iterrows():\n",
    "        entities = str(row[column]).split(',')  # Convert to string and split\n",
    "        entities = [e.strip() for e in entities]  # Strip whitespace\n",
    "        \n",
    "        if len(entities) > 3:\n",
    "            df.at[i, f\"{column}_1\"] = entities[0]\n",
    "            df.at[i, f\"{column}_2\"] = entities[1]\n",
    "            df.at[i, f\"{column}_3\"] = entities[2]\n",
    "            df.at[i, f\"{column}_4\"] = entities[3]\n",
    "        elif len(entities) == 3:\n",
    "            df.at[i, f\"{column}_1\"] = entities[0]\n",
    "            df.at[i, f\"{column}_2\"] = entities[1]\n",
    "            df.at[i, f\"{column}_3\"] = entities[2]\n",
    "            df.at[i, f\"{column}_4\"] = None\n",
    "        elif len(entities) == 2:\n",
    "            df.at[i, f\"{column}_1\"] = entities[0]\n",
    "            df.at[i, f\"{column}_2\"] = entities[1]\n",
    "            df.at[i, f\"{column}_3\"] = None\n",
    "            df.at[i, f\"{column}_4\"] = None\n",
    "        else:\n",
    "            df.at[i, f\"{column}_1\"] = entities[0]\n",
    "            df.at[i, f\"{column}_2\"] = None\n",
    "            df.at[i, f\"{column}_3\"] = None\n",
    "            df.at[i, f\"{column}_4\"] = None\n",
    "    \n",
    "    return df\n",
    "def tf_idf_vectorizer(df: pd.DataFrame, column: str):    \n",
    "    # Initialize vectorizer\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    \n",
    "    # Fit and transform the column\n",
    "    try:\n",
    "        vectors = vectorizer.fit_transform(df[column].fillna(''))\n",
    "        # Convert to dense array for easier handling\n",
    "        dense_vectors = vectors.todense()\n",
    "        \n",
    "        # Replace column with vectorized version\n",
    "        df[column] = list(dense_vectors)\n",
    "        with open(\"./../data/{column}_vectorizer.pkl\", \"wb\") as f:\n",
    "            pickle.dump(vectorizer, f)\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"Error vectorizing {column}: {str(e)}\")\n",
    "        return df\n",
    "\n",
    "#function to get embeddings\n",
    "def get_response(data):\n",
    "    api_key = os.getenv(\"JINA_API_KEY\")\n",
    "    URL = \"https://api.jina.ai/v1/embeddings\"\n",
    "\n",
    "    resp = requests.post(URL, headers={\"Authorization\": f\"Bearer {api_key}\"}, json={\"input\": data, \"model\" : \"jina-embeddings-v3\", \"task\" : \"classification\"})\n",
    "    return resp.json()[\"data\"][0][\"embedding\"]\n",
    "\n",
    "def get_embeddings(df, columns):\n",
    "    for i, row in df.iterrows():\n",
    "        for column in columns:\n",
    "            try:\n",
    "                if pd.notna(row[column]):\n",
    "                    df.at[i, column] = get_response(str(row[column]))\n",
    "                if i % 10 == 0:  # Print progress every 10 rows\n",
    "                    print(f\"Processing row {i}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {column} at row {i}: {str(e)}\")\n",
    "                df.at[i, column] = None\n",
    "    return df\n",
    "\n",
    "def parse_experience_req(col, df):\n",
    "\n",
    "    #Read the first number encountered in the string\n",
    "    df[col] = df[col].str.extract(r'(\\d+)').astype(float)\n",
    "\n",
    "def preprocess_certain_cols(df, column, na_value = \"MISSING\"):\n",
    "    \n",
    "    df[column] = df[column].fillna(na_value)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>skills</th>\n",
       "      <th>responsibilities</th>\n",
       "      <th>job_position_name</th>\n",
       "      <th>educational_requirements</th>\n",
       "      <th>experience_requirement</th>\n",
       "      <th>job_responsibilities</th>\n",
       "      <th>skills_required</th>\n",
       "      <th>matched_score</th>\n",
       "      <th>educational_institution_name_1</th>\n",
       "      <th>educational_institution_name_2</th>\n",
       "      <th>role_positions_1</th>\n",
       "      <th>role_positions_2</th>\n",
       "      <th>degree_names_1</th>\n",
       "      <th>degree_names_2</th>\n",
       "      <th>degree_names_3</th>\n",
       "      <th>degree_names_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[[[[0. 0. 0. ... 0. 0. 0.]]]]]</td>\n",
       "      <td>[[[[[0.         0.         0.         0.      ...</td>\n",
       "      <td>[[[[[0.         0.         0.         0.      ...</td>\n",
       "      <td>[[[[[0.         0.         0.         0.      ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[[[[[0.         0.         0.         0.      ...</td>\n",
       "      <td>[[[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0....</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>[[[[[0.         0.         0.         0.      ...</td>\n",
       "      <td>[[[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0....</td>\n",
       "      <td>[[[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0....</td>\n",
       "      <td>[[[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0....</td>\n",
       "      <td>[[[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0....</td>\n",
       "      <td>[[[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0....</td>\n",
       "      <td>[[[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0....</td>\n",
       "      <td>[[[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[[[[0. 0. 0. ... 0. 0. 0.]]]]]</td>\n",
       "      <td>[[[[[0.         0.         0.         0.      ...</td>\n",
       "      <td>[[[[[0.         0.         0.         0.      ...</td>\n",
       "      <td>[[[[[0.         0.         0.         0.285165...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>[[[[[0.         0.         0.         0.      ...</td>\n",
       "      <td>[[[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0....</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>[[[[[0.         0.         0.         0.      ...</td>\n",
       "      <td>[[[[[0.         0.         0.         0.      ...</td>\n",
       "      <td>[[[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0....</td>\n",
       "      <td>[[[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0....</td>\n",
       "      <td>[[[[[0.         0.         0.         0.      ...</td>\n",
       "      <td>[[[[[0.         0.         0.         0.      ...</td>\n",
       "      <td>[[[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0....</td>\n",
       "      <td>[[[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[[[[0. 0. 0. ... 0. 0. 0.]]]]]</td>\n",
       "      <td>[[[[[0.         0.         0.         0.      ...</td>\n",
       "      <td>[[[[[0.         0.         0.         0.      ...</td>\n",
       "      <td>[[[[[0.         0.43813845 0.         0.      ...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>[[[[[0.         0.         0.         0.      ...</td>\n",
       "      <td>[[[[[0.         0.         0.         0.319322...</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>[[[[[0.         0.         0.         0.      ...</td>\n",
       "      <td>[[[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0....</td>\n",
       "      <td>[[[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0....</td>\n",
       "      <td>[[[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0....</td>\n",
       "      <td>[[[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0....</td>\n",
       "      <td>[[[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0....</td>\n",
       "      <td>[[[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0....</td>\n",
       "      <td>[[[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[[[[0. 0. 0. ... 0. 0. 0.]]]]]</td>\n",
       "      <td>[[[[[0.         0.         0.         0.      ...</td>\n",
       "      <td>[[[[[0.         0.         0.         0.      ...</td>\n",
       "      <td>[[[[[0.         0.         0.         0.      ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[[[[[0.         0.         0.         0.      ...</td>\n",
       "      <td>[[[[[0.         0.         0.36023539 0.      ...</td>\n",
       "      <td>0.760000</td>\n",
       "      <td>[[[[[0.         0.         0.         0.      ...</td>\n",
       "      <td>[[[[[0.         0.         0.         0.      ...</td>\n",
       "      <td>[[[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0....</td>\n",
       "      <td>[[[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0....</td>\n",
       "      <td>[[[[[0.         0.         0.         0.      ...</td>\n",
       "      <td>[[[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0....</td>\n",
       "      <td>[[[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0....</td>\n",
       "      <td>[[[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[[[[0. 0. 0. ... 0. 0. 0.]]]]]</td>\n",
       "      <td>[[[[[0.         0.         0.         0.      ...</td>\n",
       "      <td>[[[[[0.         0.         0.         0.      ...</td>\n",
       "      <td>[[[[[0.         0.         0.         0.      ...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>[[[[[0.         0.         0.         0.      ...</td>\n",
       "      <td>[[[[[0.         0.         0.         0.      ...</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>[[[[[0.         0.         0.         0.      ...</td>\n",
       "      <td>[[[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0....</td>\n",
       "      <td>[[[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0....</td>\n",
       "      <td>[[[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0....</td>\n",
       "      <td>[[[[[0.         0.         0.         0.      ...</td>\n",
       "      <td>[[[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0....</td>\n",
       "      <td>[[[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0....</td>\n",
       "      <td>[[[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9539</th>\n",
       "      <td>[[[[[0. 0. 0. ... 0. 0. 0.]]]]]</td>\n",
       "      <td>[[[[[0.         0.         0.         0.      ...</td>\n",
       "      <td>[[[[[0.         0.         0.         0.      ...</td>\n",
       "      <td>[[[[[0.         0.         0.         0.      ...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>[[[[[0.         0.         0.         0.      ...</td>\n",
       "      <td>[[[[[0.         0.         0.         0.      ...</td>\n",
       "      <td>0.683333</td>\n",
       "      <td>[[[[[0.         0.         0.         0.      ...</td>\n",
       "      <td>[[[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0....</td>\n",
       "      <td>[[[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0....</td>\n",
       "      <td>[[[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0....</td>\n",
       "      <td>[[[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0....</td>\n",
       "      <td>[[[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0....</td>\n",
       "      <td>[[[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0....</td>\n",
       "      <td>[[[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9540</th>\n",
       "      <td>[[[[[0. 0. 0. ... 0. 0. 0.]]]]]</td>\n",
       "      <td>[[[[[0.         0.         0.         0.      ...</td>\n",
       "      <td>[[[[[0.         0.         0.         0.      ...</td>\n",
       "      <td>[[[[[0.         0.         0.         0.      ...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>[[[[[0.         0.         0.         0.      ...</td>\n",
       "      <td>[[[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0....</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>[[[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0....</td>\n",
       "      <td>[[[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0....</td>\n",
       "      <td>[[[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0....</td>\n",
       "      <td>[[[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0....</td>\n",
       "      <td>[[[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0....</td>\n",
       "      <td>[[[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0....</td>\n",
       "      <td>[[[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0....</td>\n",
       "      <td>[[[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9541</th>\n",
       "      <td>[[[[[0. 0. 0. ... 0. 0. 0.]]]]]</td>\n",
       "      <td>[[[[[0.         0.         0.         0.      ...</td>\n",
       "      <td>[[[[[0.         0.         0.         0.      ...</td>\n",
       "      <td>[[[[[0.46336169 0.         0.55147701 0.      ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[[[[[0.         0.         0.         0.      ...</td>\n",
       "      <td>[[[[[0.         0.         0.         0.      ...</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>[[[[[0.         0.         0.         0.      ...</td>\n",
       "      <td>[[[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0....</td>\n",
       "      <td>[[[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0....</td>\n",
       "      <td>[[[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0....</td>\n",
       "      <td>[[[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0....</td>\n",
       "      <td>[[[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0....</td>\n",
       "      <td>[[[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0....</td>\n",
       "      <td>[[[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9542</th>\n",
       "      <td>[[[[[0. 0. 0. ... 0. 0. 0.]]]]]</td>\n",
       "      <td>[[[[[0.         0.         0.         0.182734...</td>\n",
       "      <td>[[[[[0.         0.         0.51945643 0.      ...</td>\n",
       "      <td>[[[[[0.         0.         0.         0.      ...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>[[[[[0.         0.         0.         0.182734...</td>\n",
       "      <td>[[[[[0.         0.         0.         0.      ...</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>[[[[[0.         0.         0.         0.      ...</td>\n",
       "      <td>[[[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0....</td>\n",
       "      <td>[[[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0....</td>\n",
       "      <td>[[[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0....</td>\n",
       "      <td>[[[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0....</td>\n",
       "      <td>[[[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0....</td>\n",
       "      <td>[[[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0....</td>\n",
       "      <td>[[[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9543</th>\n",
       "      <td>[[[[[0. 0. 0. ... 0. 0. 0.]]]]]</td>\n",
       "      <td>[[[[[0.         0.         0.         0.      ...</td>\n",
       "      <td>[[[[[0.         0.         0.         0.      ...</td>\n",
       "      <td>[[[[[0.         0.         0.         0.      ...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>[[[[[0.         0.         0.         0.      ...</td>\n",
       "      <td>[[[[[0.         0.         0.         0.      ...</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>[[[[[0.         0.         0.         0.      ...</td>\n",
       "      <td>[[[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0....</td>\n",
       "      <td>[[[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0....</td>\n",
       "      <td>[[[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0....</td>\n",
       "      <td>[[[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0....</td>\n",
       "      <td>[[[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0....</td>\n",
       "      <td>[[[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0....</td>\n",
       "      <td>[[[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9544 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               skills  \\\n",
       "0     [[[[[0. 0. 0. ... 0. 0. 0.]]]]]   \n",
       "1     [[[[[0. 0. 0. ... 0. 0. 0.]]]]]   \n",
       "2     [[[[[0. 0. 0. ... 0. 0. 0.]]]]]   \n",
       "3     [[[[[0. 0. 0. ... 0. 0. 0.]]]]]   \n",
       "4     [[[[[0. 0. 0. ... 0. 0. 0.]]]]]   \n",
       "...                               ...   \n",
       "9539  [[[[[0. 0. 0. ... 0. 0. 0.]]]]]   \n",
       "9540  [[[[[0. 0. 0. ... 0. 0. 0.]]]]]   \n",
       "9541  [[[[[0. 0. 0. ... 0. 0. 0.]]]]]   \n",
       "9542  [[[[[0. 0. 0. ... 0. 0. 0.]]]]]   \n",
       "9543  [[[[[0. 0. 0. ... 0. 0. 0.]]]]]   \n",
       "\n",
       "                                       responsibilities  \\\n",
       "0     [[[[[0.         0.         0.         0.      ...   \n",
       "1     [[[[[0.         0.         0.         0.      ...   \n",
       "2     [[[[[0.         0.         0.         0.      ...   \n",
       "3     [[[[[0.         0.         0.         0.      ...   \n",
       "4     [[[[[0.         0.         0.         0.      ...   \n",
       "...                                                 ...   \n",
       "9539  [[[[[0.         0.         0.         0.      ...   \n",
       "9540  [[[[[0.         0.         0.         0.      ...   \n",
       "9541  [[[[[0.         0.         0.         0.      ...   \n",
       "9542  [[[[[0.         0.         0.         0.182734...   \n",
       "9543  [[[[[0.         0.         0.         0.      ...   \n",
       "\n",
       "                                      job_position_name  \\\n",
       "0     [[[[[0.         0.         0.         0.      ...   \n",
       "1     [[[[[0.         0.         0.         0.      ...   \n",
       "2     [[[[[0.         0.         0.         0.      ...   \n",
       "3     [[[[[0.         0.         0.         0.      ...   \n",
       "4     [[[[[0.         0.         0.         0.      ...   \n",
       "...                                                 ...   \n",
       "9539  [[[[[0.         0.         0.         0.      ...   \n",
       "9540  [[[[[0.         0.         0.         0.      ...   \n",
       "9541  [[[[[0.         0.         0.         0.      ...   \n",
       "9542  [[[[[0.         0.         0.51945643 0.      ...   \n",
       "9543  [[[[[0.         0.         0.         0.      ...   \n",
       "\n",
       "                               educational_requirements  \\\n",
       "0     [[[[[0.         0.         0.         0.      ...   \n",
       "1     [[[[[0.         0.         0.         0.285165...   \n",
       "2     [[[[[0.         0.43813845 0.         0.      ...   \n",
       "3     [[[[[0.         0.         0.         0.      ...   \n",
       "4     [[[[[0.         0.         0.         0.      ...   \n",
       "...                                                 ...   \n",
       "9539  [[[[[0.         0.         0.         0.      ...   \n",
       "9540  [[[[[0.         0.         0.         0.      ...   \n",
       "9541  [[[[[0.46336169 0.         0.55147701 0.      ...   \n",
       "9542  [[[[[0.         0.         0.         0.      ...   \n",
       "9543  [[[[[0.         0.         0.         0.      ...   \n",
       "\n",
       "      experience_requirement  \\\n",
       "0                        1.0   \n",
       "1                        5.0   \n",
       "2                        3.0   \n",
       "3                        1.0   \n",
       "4                        4.0   \n",
       "...                      ...   \n",
       "9539                     5.0   \n",
       "9540                     3.0   \n",
       "9541                     1.0   \n",
       "9542                     5.0   \n",
       "9543                     5.0   \n",
       "\n",
       "                                   job_responsibilities  \\\n",
       "0     [[[[[0.         0.         0.         0.      ...   \n",
       "1     [[[[[0.         0.         0.         0.      ...   \n",
       "2     [[[[[0.         0.         0.         0.      ...   \n",
       "3     [[[[[0.         0.         0.         0.      ...   \n",
       "4     [[[[[0.         0.         0.         0.      ...   \n",
       "...                                                 ...   \n",
       "9539  [[[[[0.         0.         0.         0.      ...   \n",
       "9540  [[[[[0.         0.         0.         0.      ...   \n",
       "9541  [[[[[0.         0.         0.         0.      ...   \n",
       "9542  [[[[[0.         0.         0.         0.182734...   \n",
       "9543  [[[[[0.         0.         0.         0.      ...   \n",
       "\n",
       "                                        skills_required  matched_score  \\\n",
       "0     [[[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0....       0.850000   \n",
       "1     [[[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0....       0.750000   \n",
       "2     [[[[[0.         0.         0.         0.319322...       0.416667   \n",
       "3     [[[[[0.         0.         0.36023539 0.      ...       0.760000   \n",
       "4     [[[[[0.         0.         0.         0.      ...       0.650000   \n",
       "...                                                 ...            ...   \n",
       "9539  [[[[[0.         0.         0.         0.      ...       0.683333   \n",
       "9540  [[[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0....       0.650000   \n",
       "9541  [[[[[0.         0.         0.         0.      ...       0.650000   \n",
       "9542  [[[[[0.         0.         0.         0.      ...       0.650000   \n",
       "9543  [[[[[0.         0.         0.         0.      ...       0.650000   \n",
       "\n",
       "                         educational_institution_name_1  \\\n",
       "0     [[[[[0.         0.         0.         0.      ...   \n",
       "1     [[[[[0.         0.         0.         0.      ...   \n",
       "2     [[[[[0.         0.         0.         0.      ...   \n",
       "3     [[[[[0.         0.         0.         0.      ...   \n",
       "4     [[[[[0.         0.         0.         0.      ...   \n",
       "...                                                 ...   \n",
       "9539  [[[[[0.         0.         0.         0.      ...   \n",
       "9540  [[[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0....   \n",
       "9541  [[[[[0.         0.         0.         0.      ...   \n",
       "9542  [[[[[0.         0.         0.         0.      ...   \n",
       "9543  [[[[[0.         0.         0.         0.      ...   \n",
       "\n",
       "                         educational_institution_name_2  \\\n",
       "0     [[[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0....   \n",
       "1     [[[[[0.         0.         0.         0.      ...   \n",
       "2     [[[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0....   \n",
       "3     [[[[[0.         0.         0.         0.      ...   \n",
       "4     [[[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0....   \n",
       "...                                                 ...   \n",
       "9539  [[[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0....   \n",
       "9540  [[[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0....   \n",
       "9541  [[[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0....   \n",
       "9542  [[[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0....   \n",
       "9543  [[[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0....   \n",
       "\n",
       "                                       role_positions_1  \\\n",
       "0     [[[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0....   \n",
       "1     [[[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0....   \n",
       "2     [[[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0....   \n",
       "3     [[[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0....   \n",
       "4     [[[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0....   \n",
       "...                                                 ...   \n",
       "9539  [[[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0....   \n",
       "9540  [[[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0....   \n",
       "9541  [[[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0....   \n",
       "9542  [[[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0....   \n",
       "9543  [[[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0....   \n",
       "\n",
       "                                       role_positions_2  \\\n",
       "0     [[[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0....   \n",
       "1     [[[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0....   \n",
       "2     [[[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0....   \n",
       "3     [[[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0....   \n",
       "4     [[[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0....   \n",
       "...                                                 ...   \n",
       "9539  [[[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0....   \n",
       "9540  [[[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0....   \n",
       "9541  [[[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0....   \n",
       "9542  [[[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0....   \n",
       "9543  [[[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0....   \n",
       "\n",
       "                                         degree_names_1  \\\n",
       "0     [[[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0....   \n",
       "1     [[[[[0.         0.         0.         0.      ...   \n",
       "2     [[[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0....   \n",
       "3     [[[[[0.         0.         0.         0.      ...   \n",
       "4     [[[[[0.         0.         0.         0.      ...   \n",
       "...                                                 ...   \n",
       "9539  [[[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0....   \n",
       "9540  [[[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0....   \n",
       "9541  [[[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0....   \n",
       "9542  [[[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0....   \n",
       "9543  [[[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0....   \n",
       "\n",
       "                                         degree_names_2  \\\n",
       "0     [[[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0....   \n",
       "1     [[[[[0.         0.         0.         0.      ...   \n",
       "2     [[[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0....   \n",
       "3     [[[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0....   \n",
       "4     [[[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0....   \n",
       "...                                                 ...   \n",
       "9539  [[[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0....   \n",
       "9540  [[[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0....   \n",
       "9541  [[[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0....   \n",
       "9542  [[[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0....   \n",
       "9543  [[[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0....   \n",
       "\n",
       "                                         degree_names_3  \\\n",
       "0     [[[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0....   \n",
       "1     [[[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0....   \n",
       "2     [[[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0....   \n",
       "3     [[[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0....   \n",
       "4     [[[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0....   \n",
       "...                                                 ...   \n",
       "9539  [[[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0....   \n",
       "9540  [[[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0....   \n",
       "9541  [[[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0....   \n",
       "9542  [[[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0....   \n",
       "9543  [[[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0....   \n",
       "\n",
       "                                         degree_names_4  \n",
       "0     [[[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0....  \n",
       "1     [[[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0....  \n",
       "2     [[[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0....  \n",
       "3     [[[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0....  \n",
       "4     [[[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0....  \n",
       "...                                                 ...  \n",
       "9539  [[[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0....  \n",
       "9540  [[[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0....  \n",
       "9541  [[[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0....  \n",
       "9542  [[[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0....  \n",
       "9543  [[[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0....  \n",
       "\n",
       "[9544 rows x 16 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ast import parse\n",
    "\n",
    "\n",
    "columns_to_ignore = [\"address\",'passing_years', 'educational_results', 'result_types', 'major_field_of_studies','professional_company_names', 'company_urls', 'related_skils_in_job', 'positions','locations','extra_curricular_activity_types','extra_curricular_organization_names','extra_curricular_organization_links', 'languages','proficiency_levels', 'certification_providers', 'certification_skills','online_links', 'issue_dates', 'expiry_dates', \"educational_institution_name\", \"role_positions\",\"degree_names\", \"career_objective\", \"start_dates\", \"end_dates\", \"age_requirement\"]\n",
    "\n",
    "#Add date_time\n",
    "#For startdates\n",
    "# df['start_dates'] = df['start_dates'].apply(lambda x : parse_date(x[0]) if isinstance(x, (list, tuple)) else x)\n",
    "\n",
    "\n",
    "#For enddates\n",
    "# def till_date_parsing(date):\n",
    "#     if date == 'Till Date' or date == 'Present':\n",
    "#         return pd.to_datetime('today')\n",
    "#     else:\n",
    "#         return date\n",
    "# df.end_dates = df.end_dates.apply(till_date_parsing)\n",
    "# # Date processing\n",
    "# df['end_dates'] = df['end_dates'].apply(lambda x : parse_date(x[0]) if isinstance(x, (list, tuple)) else x)\n",
    "\n",
    "#Modify columns in dataframe\n",
    "\n",
    "#Add experience duration\n",
    "# df['experience_duration'] = df.end_dates - df.start_dates\n",
    "\n",
    "#create two columns for top two entities\n",
    "get_top_two_entities(df, \"educational_institution_name\")\n",
    "get_top_two_entities(df, \"role_positions\")\n",
    "get_top_four_entities(df, \"degree_names\")\n",
    "\n",
    "#rename_columns\n",
    "rename_cols = {\n",
    "    \"educationaL_requirements\" : \"educational_requirements\",\n",
    "    'experiencere_requirement' : 'experience_requirement',\n",
    "    'responsibilities.1' : 'job_responsibilities',\n",
    "    \"﻿job_position_name\" : \"job_position_name\",\n",
    "}\n",
    "df.rename(columns=rename_cols, inplace=True)\n",
    "#vectorize small features\n",
    "#conconate all the entities in the list to a single string\n",
    "df['skills'] = df['skills'].apply(lambda x: ' '.join(x) if isinstance(x, (list, tuple)) else str(x))\n",
    "tf_idf_vectorizer(df, \"skills\")\n",
    "df['skills_required'] = df['skills_required'].apply(lambda x: ' '.join(x).split('\\n') if isinstance(x, (list, tuple)) else str(x))\n",
    "tf_idf_vectorizer(df, \"skills_required\")\n",
    "df['responsibilities'] = df['responsibilities'].apply(lambda x: ' '.join(x).split('\\n') if isinstance(x, (list, tuple)) else str(x))\n",
    "df[\"job_responsibilities\"] = df[\"job_responsibilities\"].apply(lambda x: ' '.join(x).split('\\n') if isinstance(x, (list, tuple)) else str(x))\n",
    "tf_idf_vectorizer(df, \"responsibilities\")\n",
    "tf_idf_vectorizer(df, \"job_position_name\")\n",
    "#parse experience requirement\n",
    "parse_experience_req(\"experience_requirement\", df)\n",
    "\n",
    "#drop columns\n",
    "df = df.drop(columns=columns_to_ignore, errors='ignore')\n",
    "\n",
    "#Fill missing vals in educational_req\n",
    "df.educational_requirements = df.educational_requirements.fillna(df.educational_requirements.mode()[0])\n",
    "df.experience_requirement = df.experience_requirement.fillna(df.experience_requirement.median())\n",
    "\n",
    "#Preprocess certain columns\n",
    "df = preprocess_certain_cols(df, \"job_responsibilities\")\n",
    "df = preprocess_certain_cols(df, \"educational_institution_name_2\")\n",
    "df = preprocess_certain_cols(df, \"role_positions_2\")\n",
    "df = preprocess_certain_cols(df, \"degree_names_2\")\n",
    "df = preprocess_certain_cols(df, \"degree_names_3\")\n",
    "df = preprocess_certain_cols(df, \"degree_names_4\")\n",
    "\n",
    "#tf idf again\n",
    "tf_idf_vectorizer(df, \"job_responsibilities\")\n",
    "tf_idf_vectorizer(df, \"educational_requirements\")\n",
    "tf_idf_vectorizer(df, \"educational_institution_name_1\")\n",
    "tf_idf_vectorizer(df, \"educational_institution_name_2\")\n",
    "tf_idf_vectorizer(df, \"role_positions_1\")\n",
    "tf_idf_vectorizer(df, \"role_positions_2\")\n",
    "tf_idf_vectorizer(df, \"degree_names_1\")\n",
    "tf_idf_vectorizer(df, \"degree_names_2\")\n",
    "tf_idf_vectorizer(df, \"degree_names_3\")\n",
    "tf_idf_vectorizer(df, \"degree_names_4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bhaskar/miniconda3/lib/python3.12/site-packages/torch/nn/modules/loss.py:610: UserWarning: Using a target size (torch.Size([7635])) that is different to the input size (torch.Size([7635, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10, Loss: 0.0385\n",
      "Predictions: tensor([[0.5759],\n",
      "        [0.5689],\n",
      "        [0.5562],\n",
      "        [0.5752],\n",
      "        [0.5735]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assume df contains sparse vectors in the given columns\n",
    "sparse_cols = [\"skills\", \"responsibilities\", \"job_position_name\", \n",
    "               \"educational_requirements\", \"job_responsibilities\", \n",
    "               \"skills_required\", \"educational_institution_name_1\",\n",
    "               \"educational_institution_name_2\", \"role_positions_1\", \n",
    "               \"role_positions_2\", \"degree_names_1\", \"degree_names_2\", \n",
    "               \"degree_names_3\", \"degree_names_4\"]\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "sparse_cols = [\"skills\", \"responsibilities\", \"job_position_name\", \"educational_requirements\", \n",
    "               \"job_responsibilities\", \"skills_required\", \"educational_institution_name_1\",\n",
    "               \"educational_institution_name_2\", \"role_positions_1\", \"role_positions_2\",\n",
    "               \"degree_names_1\", \"degree_names_2\", \"degree_names_3\", \"degree_names_4\"]\n",
    "\n",
    "# Convert sparse vector columns into proper NumPy arrays\n",
    "X_sparse = np.hstack([np.stack(df[col].to_numpy()) for col in sparse_cols])  # Ensures proper 2D structure\n",
    "\n",
    "# Extract non-embedding features\n",
    "X_other = df.drop(columns=[\"matched_score\"] + sparse_cols).to_numpy(dtype = np.float32)  # Converts remaining features to NumPy\n",
    "\n",
    "# Combine all features\n",
    "X = np.hstack((X_other, X_sparse))  # Final feature set\n",
    "\n",
    "# Target variable\n",
    "y = df[\"matched_score\"].to_numpy()\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.float32)\n",
    "\n",
    "# Define MLP Model\n",
    "class MLPModel(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(MLPModel, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_size, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 1),\n",
    "            nn.Sigmoid()  # Ensures output is between 0 and 1\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "# Instantiate model\n",
    "input_size = X_train.shape[1]  # Includes embeddings + other features\n",
    "model = MLPModel(input_size)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.MSELoss()  # Regression task\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    outputs = model(X_train_tensor)\n",
    "    loss = criterion(outputs, y_train_tensor)\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {loss.item():.4f}\")\n",
    "\n",
    "# Evaluate the model\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    y_pred = model(X_test_tensor)\n",
    "    print(\"Predictions:\", y_pred[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"./models/model.pkl\", \"wb\") as f:\n",
    "    pickle.dump(model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0.0276\n",
      "R^2 Score: 0.0005\n"
     ]
    }
   ],
   "source": [
    "#evaluate the model\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "# Calculate MSE and R^2\n",
    "mse = mean_squared_error(y_test, y_pred.numpy())\n",
    "r2 = r2_score(y_test, y_pred.numpy())\n",
    "print(f\"Mean Squared Error: {mse:.4f}\")\n",
    "print(f\"R^2 Score: {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data processing done\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "#save the dataframe\n",
    "with open(\"./data/processed_data.pkl\", \"wb\") as f:\n",
    "    pickle.dump(df, f)\n",
    "\n",
    "print(\"Data processing done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "skills                            9544\n",
       "responsibilities                  9544\n",
       "job_position_name                 9544\n",
       "educational_requirements          9544\n",
       "experience_requirement            9544\n",
       "job_responsibilities              9544\n",
       "skills_required                   9544\n",
       "matched_score                     9544\n",
       "educational_institution_name_1    9544\n",
       "educational_institution_name_2    9544\n",
       "role_positions_1                  9544\n",
       "role_positions_2                  9544\n",
       "degree_names_1                    9544\n",
       "degree_names_2                    9544\n",
       "degree_names_3                    9544\n",
       "degree_names_4                    9544\n",
       "dtype: int64"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[31mTypeError\u001b[39m: only length-1 arrays can be converted to Python scalars",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[32m/tmp/ipykernel_37376/1320959135.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     15\u001b[39m     learning_rate=\u001b[33m\"constant\"\u001b[39m,\n\u001b[32m     16\u001b[39m     learning_rate_init=\u001b[32m0.001\u001b[39m,\n\u001b[32m     17\u001b[39m     tol=\u001b[32m1e-4\u001b[39m\n\u001b[32m     18\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m mlp_model.fit(X_train, y_train)\n",
      "\u001b[32m~/miniconda3/envs/hackthon/lib/python3.12/site-packages/sklearn/base.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1385\u001b[39m                 skip_parameter_validation=(\n\u001b[32m   1386\u001b[39m                     prefer_skip_nested_validation \u001b[38;5;28;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1387\u001b[39m                 )\n\u001b[32m   1388\u001b[39m             ):\n\u001b[32m-> \u001b[39m\u001b[32m1389\u001b[39m                 \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, *args, **kwargs)\n",
      "\u001b[32m~/miniconda3/envs/hackthon/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, X, y)\u001b[39m\n\u001b[32m    750\u001b[39m         -------\n\u001b[32m    751\u001b[39m         self : object\n\u001b[32m    752\u001b[39m             Returns a trained MLP model.\n\u001b[32m    753\u001b[39m         \"\"\"\n\u001b[32m--> \u001b[39m\u001b[32m754\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m self._fit(X, y, incremental=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[32m~/miniconda3/envs/hackthon/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, X, y, incremental)\u001b[39m\n\u001b[32m    438\u001b[39m         first_pass = not hasattr(self, \"coefs_\") or (\n\u001b[32m    439\u001b[39m             \u001b[38;5;28;01mnot\u001b[39;00m self.warm_start \u001b[38;5;28;01mand\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m incremental\n\u001b[32m    440\u001b[39m         )\n\u001b[32m    441\u001b[39m \n\u001b[32m--> \u001b[39m\u001b[32m442\u001b[39m         X, y = self._validate_input(X, y, incremental, reset=first_pass)\n\u001b[32m    443\u001b[39m \n\u001b[32m    444\u001b[39m         n_samples, n_features = X.shape\n\u001b[32m    445\u001b[39m \n",
      "\u001b[32m~/miniconda3/envs/hackthon/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, X, y, incremental, reset)\u001b[39m\n\u001b[32m   1638\u001b[39m     \u001b[38;5;28;01mdef\u001b[39;00m _validate_input(self, X, y, incremental, reset):\n\u001b[32m-> \u001b[39m\u001b[32m1639\u001b[39m         X, y = validate_data(\n\u001b[32m   1640\u001b[39m             self,\n\u001b[32m   1641\u001b[39m             X,\n\u001b[32m   1642\u001b[39m             y,\n",
      "\u001b[32m~/miniconda3/envs/hackthon/lib/python3.12/site-packages/sklearn/utils/validation.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[39m\n\u001b[32m   2957\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"estimator\"\u001b[39m \u001b[38;5;28;01mnot\u001b[39;00m \u001b[38;5;28;01min\u001b[39;00m check_y_params:\n\u001b[32m   2958\u001b[39m                 check_y_params = {**default_check_params, **check_y_params}\n\u001b[32m   2959\u001b[39m             y = check_array(y, input_name=\u001b[33m\"y\"\u001b[39m, **check_y_params)\n\u001b[32m   2960\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2961\u001b[39m             X, y = check_X_y(X, y, **check_params)\n\u001b[32m   2962\u001b[39m         out = X, y\n\u001b[32m   2963\u001b[39m \n\u001b[32m   2964\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m no_val_X \u001b[38;5;28;01mand\u001b[39;00m check_params.get(\u001b[33m\"ensure_2d\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "\u001b[32m~/miniconda3/envs/hackthon/lib/python3.12/site-packages/sklearn/utils/validation.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[39m\n\u001b[32m   1366\u001b[39m         )\n\u001b[32m   1367\u001b[39m \n\u001b[32m   1368\u001b[39m     ensure_all_finite = _deprecate_force_all_finite(force_all_finite, ensure_all_finite)\n\u001b[32m   1369\u001b[39m \n\u001b[32m-> \u001b[39m\u001b[32m1370\u001b[39m     X = check_array(\n\u001b[32m   1371\u001b[39m         X,\n\u001b[32m   1372\u001b[39m         accept_sparse=accept_sparse,\n\u001b[32m   1373\u001b[39m         accept_large_sparse=accept_large_sparse,\n",
      "\u001b[32m~/miniconda3/envs/hackthon/lib/python3.12/site-packages/sklearn/utils/validation.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[39m\n\u001b[32m   1052\u001b[39m                         )\n\u001b[32m   1053\u001b[39m                     array = xp.astype(array, dtype, copy=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m   1054\u001b[39m                 \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1055\u001b[39m                     array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)\n\u001b[32m-> \u001b[39m\u001b[32m1056\u001b[39m             \u001b[38;5;28;01mexcept\u001b[39;00m ComplexWarning \u001b[38;5;28;01mas\u001b[39;00m complex_warning:\n\u001b[32m   1057\u001b[39m                 raise ValueError(\n\u001b[32m   1058\u001b[39m                     \u001b[33m\"Complex data not supported\\n{}\\n\"\u001b[39m.format(array)\n\u001b[32m   1059\u001b[39m                 ) \u001b[38;5;28;01mfrom\u001b[39;00m complex_warning\n",
      "\u001b[32m~/miniconda3/envs/hackthon/lib/python3.12/site-packages/sklearn/utils/_array_api.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(array, dtype, order, copy, xp, device)\u001b[39m\n\u001b[32m    835\u001b[39m         \u001b[38;5;66;03m# Use NumPy API to support order\u001b[39;00m\n\u001b[32m    836\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m copy \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m    837\u001b[39m             array = numpy.array(array, order=order, dtype=dtype)\n\u001b[32m    838\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m839\u001b[39m             array = numpy.asarray(array, order=order, dtype=dtype)\n\u001b[32m    840\u001b[39m \n\u001b[32m    841\u001b[39m         \u001b[38;5;66;03m# At this point array is a NumPy ndarray. We convert it to an array\u001b[39;00m\n\u001b[32m    842\u001b[39m         \u001b[38;5;66;03m# container that is consistent with the input's namespace.\u001b[39;00m\n",
      "\u001b[32m~/miniconda3/envs/hackthon/lib/python3.12/site-packages/pandas/core/generic.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, dtype, copy)\u001b[39m\n\u001b[32m   2149\u001b[39m     def __array__(\n\u001b[32m   2150\u001b[39m         self, dtype: npt.DTypeLike | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m, copy: bool_t | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   2151\u001b[39m     ) -> np.ndarray:\n\u001b[32m   2152\u001b[39m         values = self._values\n\u001b[32m-> \u001b[39m\u001b[32m2153\u001b[39m         arr = np.asarray(values, dtype=dtype)\n\u001b[32m   2154\u001b[39m         if (\n\u001b[32m   2155\u001b[39m             astype_is_view(values.dtype, arr.dtype)\n\u001b[32m   2156\u001b[39m             \u001b[38;5;28;01mand\u001b[39;00m using_copy_on_write()\n",
      "\u001b[31mValueError\u001b[39m: setting an array element with a sequence."
     ]
    }
   ],
   "source": [
    "#Build a ml model\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "X,y  = df.drop(columns=[\"matched_score\"]), df[\"matched_score\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "input_feature_size = len(X_train.columns)\n",
    "X = np.array(X.tolist())  # Converts lists to a proper NumPy array\n",
    "mlp_model = MLPRegressor(\n",
    "    hidden_layer_sizes = (input_feature_size, 50, 10, 1),\n",
    "    activation = 'relu',\n",
    "    solver = 'adam',\n",
    "    max_iter = 20,\n",
    "    alpha=0.0001,\n",
    "    batch_size='auto', \n",
    "    learning_rate=\"constant\",\n",
    "    learning_rate_init=0.001,\n",
    "    tol=1e-4\n",
    ")\n",
    "mlp_model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
